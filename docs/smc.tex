\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{bm}

\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}
\renewcommand{\bibname}{References}
\bibliographystyle{apalike}

\newcommand{\reals}{\mathbb{R}}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\normal}{\mathcal{N}}
\newcommand{\unif}{\mathcal{U}}

\newcommand{\z}{\mathbf{z}}
\newcommand{\abold}{\mathbf{a}}
\newcommand{\y}{\mathbf{y}}
\newcommand\tdict[0]{\boldsymbol{\tau}}

\title{Sequential Monte Carlo Pseudomarginal Generative Functions}
\author{Marco Cusumano-Towner}

\begin{document}
\maketitle

\section{A generative model}
\noindent Consider a generative probabilistic model with joint distribution:
\[
p_{\theta}(\z_{1:T}, \y_{1:T}) = \left( p(z_1) \prod_{t=2}^T p(z_t | \z_{1:t-1})  \right) \left( \prod_{t=1}^T p(y_t | z_t) \right)
\]
for some parameter $\theta$.
We will omit the parameter from the notation from here forward to simplify notation.

\section{Particle filtering and conditional particle filtering}
Consider a family of proposal distributions:
\[
    k_1(z_1) \mbox{ and } k_t(z_t; \z_{1:t-1}) \mbox{ for } t \in \{2, \ldots, T\}
\]
Consider a particle filter with $N$ particles that uses the above proposal distributions at each time step, with proportional resampling at every time step.
Suppose after computing the weights at time step $T$, the particle filter resamples a single `distinguished' particle index proportionally to the weights.
Notation for the particle filter:
\begin{itemize}
    \item $z_t^{(i)}$ is the state for particle $i$ at time $t$, for $i \in \{1, \ldots, N\}$ and $t \in \{1, \ldots, T\}$.
    \item $a_{t-1}^{(i)} \in \{1, \ldots, N\}$ is the index of the parent of $z_t^{(i)}$ for $i \in \{1, \ldots, N\}$ and $t \in \{2, \ldots, T\}$.
    \item $I_T$ is the index of the distinguished particle at time $T$.
    \item $I_t := a_t^{(I_{t+1})}$ is the index of the distinguished particle at time $t$ for $t \in \{1, \ldots, T-1\}$.
    \item $\z_{1:T}^* = (z_1^{(I_1)}, z_2^{(I_2)}, \ldots, z_T^{(I_T)})$ is the distinguished particle.
    \item $w^{(i)}_1 := \displaystyle \frac{p(z_1, y_1)}{k_1(z_t)}$ is the initial weight, for $i \in \{1, \ldots, N\}$ and $t \in \{2, \ldots, T\}$.
    \item $w^{(i)}_t := \displaystyle \frac{p(z_t, y_t | \z_{1:t-1})}{k_t(z_t; \z_{1:t-1})}$ is an incremental weight, for $i \in \{1, \ldots, N\}$ and $t \in \{2, \ldots, T\}$.
    \item $\z_{1:T}^{1:N} := (z_t^{(i)})_{t \in \{1, \ldots, T\}}^{i \in 1 \ldots, N}$ is the set of all particles.
    \item $\abold_{1:T-1}^{1:N} := (a^{(i)}_{t-1})_{t \in \{2, \ldots, T\}}^{i \in \{1, \ldots, N\}}$ is the set of all ancestor choices.
\end{itemize}
The particle filter algorithm samples from the following joint distribution:
\begin{align*}
    & q_{\mathrm{SMC}}(\z_{1:T}^{1:N}, \abold_{1:T-1}^{1:N}, I_T, \z_{1:T}^*)\\
    &=  \left( \prod_{i=1}^N k_1(z_1^{(i)}) \right)
        \left( \prod_{t=2}^T \prod_{i=1}^N \frac{w_{t-1}^{(a_{t-1}^{(i)})}}{\sum_{i=1}^N w_{t-1}^{(j)}} k_t(z_t^{(i)}; \z_{1:t-1}^{(a_{t-1}^{(i)})} )\right)
        \left( \frac{w_T^{(I_T)}}{\sum_{j=1}^N w_T^{(j)}} \right)
        \delta(\z_{1:T}^*,  (z_1^{(I_1)}, \ldots, z_T^{(I_T)}))
\end{align*}
where $\delta$ denotes the Kronecker delta function, and where we assume the $z_{t}^i$ are discrete.
Given $\z_{1:T}^*$, the conditional particle filter algorithm samples from the following joint distribution:
\begin{align*}
    & r_{\mathrm{CSMC}}(\z_{1:T}^{1:N}, \abold_{1:T-1}^{1:N}, I_T; \z_{1:T}^*)\\
    &=  \delta(\z_{1:T}^*,  (z_1^{(I_1)}, \ldots, z_T^{(I_T)}))
        \left( \prod_{\substack{i=1\\i \ne I_1}}^N k_1(z_1^{(i)}) \right)
        \left( \prod_{t=2}^T \prod_{\substack{i=1\\i \ne I_t}}^N \frac{w_{t-1}^{(a_{t-1}^{(i)})}}{\sum_{i=1}^N w_{t-1}^{(j)}} k_t(z_t^{(i)}; \z_{1:t-1}^{(a_{t-1}^{(i)})} )\right)
\end{align*}

\section{Constructing a generative function}
We combine the generative model and the particle filter and conditional particle filter algorithms together to construct a generative function.
We use the notation of Section 4.5 of~\citet{cusumano-towner-thesis}.
Without loss of generality, let the arguments to the generative function be $x = (\theta, T)$ (recall that $\theta$ parametrizes the generative model joint distribution).
For argument $(\theta, T)$ the generative function places all its probability mass on choice maps of the form:
\[
\tdict = \{1 \mapsto y_1, \ldots, T \mapsto y_T\}
\]
where the probability for such a choice map $\tdict$ in terms of the underlying generative model as:
\[
    p(\tdict; (\theta, T)) := \sum_{\z_{1:T}} p(\z_{1:T}, \y_{1:T}) = p(\y_{1:T})
\]
We now endow the generative function with encapsulated randomness of the form:
\[
\omega = (\z_{1:T}^{1:N}, \abold_{1:T-1}^{1:N}, \z_{1:T}^*)
\]
We define:
\begin{align*}
\mathring{p}(\omega; (\theta, T), \tdict) &:= p(\z_{1:T}^* | y_{1:T}) r_{\mathrm{CSMC}}(\z_{1:T}^{1:N}, \abold_{1:T-1}^{1:N}, I_T; \z_{1:T}^*)\\
\mathring{q}(\omega; (\theta, T), \tdict) &:= q_{\mathrm{SMC}}(\z_{1:T}^{1:N}, \abold_{1:T-1}^{1:N}, I_T, \z_{1:T}^*)
\end{align*}
Therefore:
\begin{align*}
\xi((\theta, T), \tdict, \omega)
    &:= \frac{p(\tdict; (\theta, T)) \mathring{p}(\omega; (\theta, T), \tdict)}{\mathring{q}(\omega; (\theta, T), \tdict)}\\
    &= \frac{p(\y_{1:T}) p(\z_{1:T}^* | y_{1:T}) r_{\mathrm{CSMC}}(\z_{1:T}^{1:N}, \abold_{1:T-1}^{1:N}, I_T; \z_{1:T}^*)}{q_{\mathrm{SMC}}(\z_{1:T}^{1:N}, \abold_{1:T-1}^{1:N}, I_T, \z_{1:T}^*)}\\
    &= \prod_{t=1}^T \frac{1}{N} \sum_{i-1}^N w^{(i)}_t
\end{align*}
which is the marginal likelihood estimate from the particle filter (see~\citet{cusumano2017aide} for the derivation for the more general setting of SMC samplers with rejuvenation).

\subsection{Simulate}
The \emph{simulate} operation jointly samples $\tdict \sim p(\cdot; (\theta, T))$ and $\omega | \tdict \sim \mathring{p}(\cdot; (\theta, T), \tdict)$.
It is possible to sample from this joint distribution by:
\begin{enumerate}
\item Sampling from the joint distribution of the underlying generative model: $\z_{1:T}^*, \y_{1:T} \sim p(\cdot)$.
\item Executing the conditional particle filter algorithm given input $\z_{1:T}^*$ (the algorithm depends on $\y_{1:T}$ as well), which together with $\z_{1:T}^*$ gives the encapsulated randomness $\omega$.
\end{enumerate}
After executing conditional particle filter, $\xi((\theta, T), \tdict, \omega)$ is the particle filter marginal likelihood estimate.
The operation returns a \emph{trace} containing this estimate along with $\y_{1:T}$ and $\omega$ and the arguments $(\theta, T)$.

\subsection{Generate}
We consider \emph{generate} operation acting on constraints $\tdict = \{1 \mapsto y_1, \ldots, T \mapsto y_T\}$ (it can be extended to handle other $\y_{1:T}$ via an internal proposal distribution family that sampels the subset of $\y_t$ that were not provided given those that were).
It samples $\omega \sim \mathring{q}(\cdot; (\theta, T), \tdict)$, which in our case reduces to executing the particle filter.
Then, $\xi((\theta, T), \tdict, \omega)$ is the particle filter marginal likelihood estimate.
The operation returns a trace containing this estimate along with $\y_{1:T}$ and $\omega$ and the arguments $(\theta, T)$, as well as a \emph{weight}, which in our case reduces to $\xi((\theta, T), \tdict, \omega)$.

\subsection{Update}
The \emph{update} operation described in Section 4.5 of~\citet{cusumano-towner-thesis} samples fresh encapsulated randomness independently of the previous value of the encapsulated randomness, from $\mathring{q}$.
For our example, this amounts to running the particle filter from scratch.

\bibliography{references} 

\end{document}
